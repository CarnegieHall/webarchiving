# Web Archiving Primer

*DRAFT*

## What is Web Archiving?
"The process of selecting, capturing, saving and making accessible select content available online (e.g. websites)" - (p. 8 of [Web Archive Intro](https://www.slideshare.net/annaperricci/web-archiving-intro-circa-2015) by Anna Pericci).

Web content is very vulnerable to loss. Carnegie Hall is attempting to address this by building a web archiving strategy based with its [web archiving workplan](https://carnegiehall.github.io/webarchiving/workplan.html)

## What are Carnegie Hall's web archiving goals?
What needs are being met by web archive capture of sites?

Representation of web-based output from an individual or organization

Build in sustainability factors into creation - start preservation process at point of creation 

Do we want evidence that X site existed at this time, contained this information? Or do we want to capture the experience of using the site? ex.: sites that no longer function; how to capture the older, functioning site 

## Different types of captures

### Needs-based capture levels
Web Archiving can be done at different levels: 
1. Dynamic, curated capture to represent functionality and features
2. Low fidelity capture like high-level crawls (Wayback Machine) or even as simple as screenshots
3. Content harvest where all assets, media are captured for future management or reuse in updated capacity to align with current web goals 

![Screenshot of 1996 Carnegie Hall website](/ch1996.png)

_1996 iteration of the Carnegie Hall website (captured by and accessible in the Wayback Machine from Internet Archive)_

### Capture tools
#### Crawls
Crawler is software that indexes web content. Saved by a crawl: (also by AP)
- Code/info in web programming language (HTML, Flash)
- Some formatting (e.g., CSS)
- Text
- Images
- Some media files (embedded, but not the streamed ones)
- Documents, spreadsheets, presentations, data sets (XML, PDF, CSV)

Archive-It
Wget

#### Curated captures
Need project-by-project goal, as each site is unique. What is worthy of capture? What quality do we expect from each capture? 

Webrecorder

#### Web Archiving formats

WARC

#### Viewing captured sites

Wayback Machine
Webrecorder (UI and Player)
Emulation



